---
title: "Computer Assisted Mass Appraisal - Residential"
output:
  html_document:
    highlight: pygments
    number_sections: yes
    theme: journal
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

## Introduction.

*Is it possible to create a predictive model to predict sale price of residential properties in DC area?*

District of Columbia shares hundreds of datasets which can be used for analysis and planning by different agencies and public.

Computer Assisted Mass Appraisal (CAMA) database is one the interesting datasets with residential appraisals. The dataset contains attribution on housing characteristics for residential properties, and was created as part of the DC Geographic Information System (DC GIS) for the DC Office of the Chief Technology Officer (OCTO) and participating D.C. government agencies.  
For more details see <http://opendata.dc.gov/datasets/computer-assisted-mass-appraisal-residential>.


Technical aspects expected to be showcased in this project are.  

1. Exloratory Data Analysis.  
2. Data wrangling.  
3. Data merging.  
4. Visual analysis of data.  
5. Regression models.  
6. Presentation tools.  

## Set up.  

Setup libraries and data needed for machine learning.  


### Load Libraries
```{r load_libraries, warning=FALSE, message=FALSE}
library(readr) # reading csv file
library(ggplot2) # plotting
library(tibble) # enhanced dataframe
library(dplyr) # data manipulation
library(tidyr) # tidying the data
library(lubridate)# date manipulation
library(docstring) # document function 
library(Hmisc) # correlations
library(corrplot) # plotting correlations.
library(caret)
library(e1071)
library(randomForest)
library(import)
library(xgboost)
library(glmnet)
library(stats)
```

### Reusable functions.  
```{r re_usable_functions}
draw_bar_graph <- function(col_name, graph_title, xlabel){
  #' Draw horizontal bar chart for col_name in descending order of frequency.
  col_name_en <- enquo(col_name)
  residential_clean_df %>%
  select(!!col_name_en) %>%
  group_by(!!col_name_en) %>%
  summarise(ftr_count = n()) %>%
  arrange(desc(ftr_count)) %>%
  ggplot( data = ., aes(x = reorder(!!col_name_en,ftr_count), y = ftr_count)) +
  geom_bar(stat = 'identity') +
  coord_flip()+
  labs(title = graph_title) +
  ylab('Residence count') +
  xlab(xlabel)
}

draw_boxplot_graph <- function(col_name, col_name_d, graph_title, excl_list){
  #' draw boxplot for each categories in col_name_d by PRICE
  col_name <- enquo(col_name)
  excl_list <- enquo(excl_list)
  col_name_d1 <- enquo(col_name_d)
  residential_clean_df %>%
  filter(!(!!col_name %in% !!excl_list) ) %>%
  select(!! col_name_d1, PRICE) %>%
  ggplot(data = ., aes(x = get(col_name_d), y=PRICE^0.5)) +
  geom_boxplot() +
  coord_flip() +
  labs(title = graph_title) +
  xlab(col_name_d)
}

error_plot <- function(pre,obs){
df <- as.data.frame(cbind(pre, obs))
colnames(df) <- c('pred','obs')
ggplot(data = df, aes(x = pred, y = obs-pred)) +
  geom_point(shape = 1)+
  geom_abline(slope = 0, intercept = 0, color = 'red') +
  geom_smooth(method = 'loess') +
  labs(x = 'Fitted Values',y = 'Residuals', 
       title = 'Residuals Vs Fitted',
       caption = 'No pattern indicated good model')
}
```
model_diagnostic_plots(exp(lm_predict), test_residence_df$PRICE, 'Linear Regression')

### Data Load.
```{r loaddata, echo=FALSE}
residential_raw_df <- read_csv('Data/Computer_Assisted_Mass_Appraisal__Residential.csv')
```  
```{r summary_data}
summary(residential_raw_df)
```

Object ID is serial number which will be used for merging later in.  
last variable the db updated date and SSL  is not used for predictive modelling.
These are of no importance for data analysis. Let's exclude these from the data frame.  
**SALES QUALIFICATION.**  

The basic sales information is available at the Register of Deeds. However, before a proper analysis can be made between the sales for the tax year and those of similar properties that did not sell, the sales must be checked or qualified to verify that and "arm's length" transaction has taken place and the source of information is correct. The transaction must then be further checked to determine if all rights and benefits of property ownership were transferred and if any personal property was involved. This procedure is known as SALES QUALIFICATION. Sales of some residential, but primarily agricultural, industrial and commercial properties often include personal property. There are also a number of intra-company or intra-family transfers "distress" sales, etc., many of which have limiting terms and conditions which affect the sales price. For these reasons and others, further qualification of sales of this type through communication with one or more of the parties involved may be necessary to determine if the sales price should be adjusted for terms, personal property, etc., or disqualified entirely.  

Dataset has 39 variables and 107,237 observations. Create a new df called cleaned version with only Qualified sales. Others can be used later for testing the model.  

```{r cleanData}
residential_clean_df <- residential_raw_df %>%
  select(-SSL, -GIS_LAST_MOD_DTTM) %>%
  filter(QUALIFIED == 'Q')

residential_unqualified <- residential_raw_df %>%
  select(-SSL, -GIS_LAST_MOD_DTTM) %>%
  filter(QUALIFIED == 'U') 
```

## Exploratory Data Analysis.  

Analyse all the features.  

### Heating.  

Analyse heating related columns.
```{r heat_1}
table(residential_clean_df$HEAT_D, residential_clean_df$HEAT)

#Let's draw bar graph
draw_bar_graph(HEAT_D, 'Residences by heating type','Heating Type')
```  

'Forced Air(1)', 'Hot Water Rad (13)', Warm Cool(7)' have majority of residences.
Analyse rest of categories and any apparent relation with PRICE.

```{r HEAT_2}
condition <- c(1,7,8,13)
draw_boxplot_graph(HEAT, 'HEAT_D','Heat Type vs Price',condition)
```  
  
Except one outlier all other have very similar distribution. Let's look at No Data and NA values.

```{r heat_3}
residential_clean_df %>%
  filter(is.na(HEAT_D))

# most of the columns on these 1 are NA. Let's drop these rows.
residential_clean_df <- residential_clean_df %>%
  filter(!is.na(HEAT_D))

```  
Below will be the coding.   
heat_coding = hot_water_rad if 'Hot Water Rad (13)'  
            = forced_air if 'Forced Air(1)'  
            = warm_cool if Warm Cool(7)'  
            = other_heating for all other.  
Make the column factor and remove HEAT and HEAT_D.  

```{r HEAT_CODING}
residential_clean_df <- residential_clean_df %>%
  mutate(heat_coding = case_when(HEAT == 13 ~ 'ht_hot_water_rad',
                                 HEAT == 1 ~ 'ht_forced_air',
                                 HEAT == 7 ~ 'ht_warm_cool',
                                 TRUE ~ 'ht_other')) %>%
  mutate(heat_coding = as.factor(heat_coding)) 
```

### Roof feature.  

```{r roof_1}
table(residential_clean_df$ROOF_D, residential_clean_df$ROOF)

#Let's draw bar graph
draw_bar_graph(ROOF_D, 'Residences by roof type','Roof Type')
```  
  
  
Built Up(2), Comp Shingle(1), Metal - Sms(6) and Slate(11) are majority of houses roof types. Rest of the types can be bucketted together. Before that lets see if they have any relation with PRICE.  

```{r roof_2}
condition <- c(1,2,6,11)
draw_boxplot_graph(ROOF, 'ROOF_D','Distribution of roof type by price',condition)

```  

Concrete Tile and Metal-Cpr have higher median PRICE compared to other roof types.  
However they are very small number of residences. They are all bucketted in other.
```{r roof_4}
residential_clean_df <- residential_clean_df %>%
  mutate(roof_coding = case_when(ROOF == 1 ~ 'rf_comp_shingle',
                                 ROOF == 2 ~ 'rf_built_up',
                                 ROOF == 6 ~ 'rf_metal_sms',
                                 ROOF == 11 ~ 'rf_slate',
                                 TRUE ~ 'rf_other')) %>%
  mutate(roof_coding = as.factor(roof_coding)) 

```  

### Style feature.  

```{r style_1}
table(residential_clean_df$STYLE_D, residential_clean_df$STYLE)

#Let's draw bar graph
draw_bar_graph(STYLE_D, 'Residences by Style','Style')

```
  
    
2 story(4), 3 Story(7), 2.5 Story(6) and 1 Story(1) are majority. Rest will be analsyed for relationship with price to determine the possible grouping.  

```{r style_2}
exclusion_lst <- c(4,7,6,1)
draw_boxplot_graph(STYLE, 'STYLE_D','Distribution of Price by style',exclusion_lst)
```
  
    
4 story and 3.5 story finished are grouped and rest in other.

```{r style_3}

residential_clean_df <- residential_clean_df %>%
  mutate(style_coding = case_when(STYLE == 4 ~ 'stl_2_story',
                                 STYLE == 7 ~ 'stl_3_story',
                                 STYLE == 6 ~ 'stl_2_h_story',
                                 STYLE == 1 ~ 'stl_1_story',
                                 STYLE %in% c(10,9) ~ 'stl_other_high',
                                 TRUE ~ 'stl_other')) %>%
  mutate(style_coding = as.factor(style_coding)) 
```  
  
### Structure feature.  

```{r structure_1}
table(residential_clean_df$STRUCT_D, residential_clean_df$STRUCT)

#Let's draw bar graph
draw_bar_graph(STRUCT_D, 'Residences by Structure','Structure')
```  
  
    
Row Inside(7), Single(1), Semi-detatched(8), Row_end(6) and multi(2) are clear groups.  Let's analyse others.

```{r struct_2}
exclusion_lst <- c(7,1,8,6,2)
draw_boxplot_graph(STRUCT, 'STRUCT_D','Distribution of Price by Structure',exclusion_lst)
```
  
    
Default structure has high price however there are only 3 residences. Let's group everything else into bucket.  

```{r STRUCT_3}
residential_clean_df <- residential_clean_df %>%
  mutate(structure_coding = case_when(STRUCT == 7 ~ 'str_row_inside',
                                 STRUCT == 1 ~ 'str_single',
                                 STRUCT == 8 ~ 'str_semi_detached',
                                 STRUCT == 6 ~ 'str_row_end',
                                 STRUCT == 2 ~ 'str_multi',
                                 TRUE ~ 'stl_other')) %>%
  mutate(structure_coding = as.factor(structure_coding)) 
```  
  
### Grade feature.  

```{r grade_1}
table(residential_clean_df$GRADE_D, residential_clean_df$GRADE)

#Let's draw bar graph
draw_bar_graph(GRADE_D, 'Residences by Grade','Grade')
```  

Average(3), Above average(4), very good(6) and excellent(7) are buckets. Rest are analysed.  

```{r grade_2}
exclusion_lst <- c(3,4,6,7)
draw_boxplot_graph(GRADE, 'GRADE_D','Distribution of Price by grade',exclusion_lst)
```  
  
    
```{r GRADE_3}
residential_clean_df <- residential_clean_df %>%
  mutate(grade_coding = case_when(GRADE == 3 ~ 'grade_average',
                                 GRADE == 4 ~ 'grade_above_average',
                                 GRADE == 6 ~ 'grade_very_good',
                                 GRADE == 7 ~ 'grade_excellent',
                                 TRUE ~ 'grade_other')) %>%
  mutate(grade_coding = as.factor(grade_coding)) 
```  
  
  
### Condition feature.  

```{r condition_1}
table(residential_clean_df$CNDTN_D, residential_clean_df$CNDTN)
```  

Condition seems to be ordered factor. let's keep CNDTN as coding.

```{r condition_2}
residential_clean_df <- residential_clean_df %>%
  mutate(condition_coding = as.numeric(CNDTN))
```  

  
### Interanl Wall feature.  

```{r INTWALL_1}
table(residential_clean_df$INTWALL_D, residential_clean_df$INTWALL)

#Let's draw bar graph
draw_bar_graph(INTWALL_D, 'Residences by internal wall','Internal Wall')
```  

Hardwood(6), Hardwood/Carp(11). Rest are analysed.  

```{r intwall_2}
exclusion_lst <- c(2,3,6,11)
draw_boxplot_graph(INTWALL, 'INTWALL_D','Distribution of Price by internal wall',exclusion_lst)
```  
  
all these can be grouped into 1.


```{r intwall_3}
residential_clean_df <- residential_clean_df %>%
  mutate(intwall_coding = case_when(EXTWALL == 2 ~ 'intwall_carpet',
                                 EXTWALL == 6 ~ 'intwall_hard_wood',
                                 TRUE ~ 'intwall_other')) %>%
  mutate(intwall_coding = as.factor(intwall_coding)) 
```  
  
### External Wall feature.  

```{r EXTWALL_1}
table(residential_clean_df$EXTWALL_D, residential_clean_df$EXTWALL)

#Let's draw bar graph
draw_bar_graph(EXTWALL_D, 'Residences by external wall','External Wall')
```  

common brick(14), Brick/siding(22), vinyl siding(4) and wood siding(6) are buckets. Rest are analysed.  

```{r extwall_2}
exclusion_lst <- c(4,6,14,22)
draw_boxplot_graph(EXTWALL, 'EXTWALL_D','Distribution of Price by external wall',exclusion_lst)
```  
  
all these can be grouped into 1.


```{r extwall_3}
residential_clean_df <- residential_clean_df %>%
  mutate(etxwall_coding = case_when(EXTWALL == 4 ~ 'extwall_vinyl_siding',
                                 EXTWALL == 6 ~ 'extwall_siding',
                                 EXTWALL == 14 ~ 'extwall_common_brick',
                                 EXTWALL == 22 ~ 'extwall_brick_siding',
                                 TRUE ~ 'extwall_other')) %>%
  mutate(etxwall_coding = as.factor(etxwall_coding)) 
```  

### Air condition.  

AC column has N, Y and 0 values. o is absence of AC which can be coded back to 'N'.  
Residences with AC should be more valuable compared to residences with no AC. So N is coded to numeric 0 and Y to 1.  


```{r AC}
residential_clean_df <- residential_clean_df %>%
  mutate(AC = if_else(AC == '0', 'N',AC))
# code N to 0 and Y to 1.
 residential_clean_df <- residential_clean_df %>%
  mutate(ac_coding = as.numeric(if_else(AC == 'N', '0','1')))

```  

### USE CODE.

Usecode. There are land use codes for each specific category. For our purpose we can group 11 to 19 to vacant and rest to non vacant.

```{r USECODE}
# 0 is vacant and 1 is non vacant
residential_clean_df <- residential_clean_df %>%
  mutate(LAND_USE = case_when(USECODE <= 19 ~ 0,
                              USECODE > 19 ~ 1)) %>%
  mutate(LAND_USE = as.factor(LAND_USE)) %>%
  select(-USECODE)

```
### Features not needed.  
1. Building Number - Building number. As per the meta data For parcels where multiple buildings exist, the primary building (such as the main residence) is assigned BLDG_NUM = 1. The other buildings or structures have BLDG_NUM values in random sequential order. So BLDG_NUM is just a number of building on a parcel which does not have any significance for the analysis. Removing the column.  
2. Bathrooms - As above.  
3. Air condition - As above.  
4. Features and thier descriptions - As above.  
 They are EXTWALL, INTWALL, GRADE, CNDTN, HEAT, STYLE, STRUCT, ROOF  
 
```{r remove_columns}
residential_clean_df <- residential_clean_df %>%
  select(-BLDG_NUM, -AC, -EXTWALL, -EXTWALL_D, -INTWALL, -INTWALL_D, -GRADE, -GRADE_D, -CNDTN, -CNDTN_D, -HEAT, -HEAT_D, -STYLE, -STYLE_D, -STRUCT, -STRUCT_D, -ROOF, -ROOF_D)
```  


## Feature Engineering.  

### Bathrooms.  

HF_BATHRM can be merged with BATHRM to create BATHROOMS_TOT variable.  
```{r bathroom_1}
residential_clean_df <- residential_clean_df %>%
  mutate(BATHROOM_TOTAL = BATHRM + 0.5*HF_BATHRM) 
summary(residential_clean_df$BATHROOM_TOTAL)
```
Check out the single record which have NA for BATHROOM_TOT

```{r bathroom_2}
residential_clean_df %>%
  filter(is.na(BATHROOM_TOTAL))
```

Only record with OBJECTID '11154' has bathroom 5 and hf_bathroom as na. Total bath room can be imputed to 5. 

```{r bathroom_3}
residential_clean_df[residential_clean_df['OBJECTID'] == 11154,'BATHROOM_TOTAL'] = 5
residential_clean_df <- residential_clean_df %>%
  filter(!is.na(BATHROOM_TOTAL)) 
```   

Removing the bathrooms columns.  

```{r bathroom_4}
residential_clean_df <- residential_clean_df %>%
  select(-BATHRM, -HF_BATHRM)
```


### Analyse data for different room types.  

They are 'ROOMS', 'BEDRM', 'KITCHENS', 'FIREPLACES', 'BATHROOM_TOTAL'

```{r fe_rooms}
residential_clean_df %>%
  select('ROOMS','BEDRM','KITCHENS','FIREPLACES','BATHROOM_TOTAL') %>%
  summary()

# Let's draw boxplots to check the data distributions.
residential_clean_df %>%
  select('ROOMS','BEDRM','KITCHENS','FIREPLACES','BATHROOM_TOTAL') %>%
  gather(key = 'room_type', value = 'room_count') %>%
  ggplot(data = ., aes(x=room_type, y = room_count )) +
  geom_boxplot() +
  labs(title = 'Distribution of number of different room', y = 'residences')
```
  
residence with 101 ROOMS is outlier. Let's investigate it.

```{r fe_rooms_2}
residential_clean_df[residential_clean_df['ROOMS'] == 101,]
# It seems to be fat fingure error. Rather ROOMS seems to be 10 looking at number of kitchens. bede room etc.

residential_clean_df[residential_clean_df$OBJECTID == 63895,]['ROOMS'] = 10

residential_clean_df[residential_clean_df$BEDRM > 20,]
```

### Year variables.  
AYB - Actual year built.  
EYB - Estimated year built.  
YR_RMDL - Year remodelled.  
SaleDate - Sale of the residential property.
Rationale of feature engineering.  
1. Take into account the depreciation. Calculate AGe of residential property at the time of sale.  
2. Age can be calculated by sale_year - max(AYB, EYB, YR_RMDL)  
3. there should be differentiation of property remodelled vs newly buit in the same year. Create one variable (factor) if the property is remodelled.  


```{r remodel}
# Out of total 27,960 remodelled houses, 16,685 are remodelled before sale year. So these should be having flag for remodelled.

residential_clean_df %>%
  filter(! is.na(YR_RMDL)) %>%
  summarise(n())

residential_clean_df %>%
  filter(YR_RMDL < year(SALEDATE)) %>%
  summarise(n())

residential_clean_df <- residential_clean_df %>%
  mutate(remodelled = if_else(YR_RMDL < year(SALEDATE), 0 ,1)) %>%
  mutate(remodelled = if_else(is.na(remodelled),1,remodelled)) %>%
  mutate(remodelled = as.factor(remodelled))
```

```{r year}
residential_clean_df %>%
  select(SALEDATE) %>%
  mutate(y1 = year(SALEDATE)) %>%
ggplot(data =., aes(y = y1)) +
  geom_boxplot()
# One record withSALEDATE 1900 has no price. Deleting it.
residential_clean_df <- residential_clean_df %>%
  filter(!year(SALEDATE) == 1900)

# there are 9 records with year_remodelled is less than actual year build and 15 records with estimated year built less than actual year build. These does not make sense. Removing these records.

year_rows_removal <- which(residential_clean_df$EYB < residential_clean_df$AYB)
year_rows_removal <- union(year_rows_removal,which(residential_clean_df$YR_RMDL < residential_clean_df$AYB)) 
residential_clean_df <- residential_clean_df[-year_rows_removal,]

residential_clean_df %>%
  select(AYB, EYB, YR_RMDL, SALEDATE, remodelled, PRICE)

# calculate age variable which is as of sale year.
residential_clean_df <- residential_clean_df %>%
  mutate(sale_year = year(SALEDATE)) %>%
  mutate(age = pmin(if_else(sale_year - AYB <0, 999,  sale_year - AYB ),
                    if_else(sale_year - EYB <0, 999,  sale_year - EYB ), 
                    if_else(sale_year - YR_RMDL <0, 999,  sale_year - YR_RMDL ), 
                    na.rm=TRUE)) 
# there are 145 records which has sale date earlier than AYB, EYB and YR_RMDL. These records are all removed.
residential_clean_df <- residential_clean_df[-which(residential_clean_df$age==999),]
# excluding the date columns
residential_clean_df <- residential_clean_df %>%
  select(-AYB, -EYB, -YR_RMDL, -SALEDATE)


ggplot(data = residential_clean_df, aes(x = sale_year))+
  geom_bar() +
  labs(title = 'Sales by year') +
  coord_flip()

# There are very few (1 or 2) sales before 1992. Removing those.

residential_clean_df <- residential_clean_df %>%
  filter(sale_year >= 1992)

# sale year should be factor. 1 year increase in sale year does not necesserily mean 1 unit increase in sale pice.  
residential_clean_df <- residential_clean_df%>%
  mutate(sale_year = as.factor(sale_year))
```

### Analyse area 
GBA and LandAREA.

```{r EDA_AREA}
residential_clean_df %>%
  select(GBA,LANDAREA) %>%
  gather(key = 'type', value = 'area') %>%
  ggplot(data = ., aes(x = type, y = area)) +
  geom_boxplot() +
  labs(title = 'Distribution of areas')
```

Lets bucket land area and GBA into 5 groups each based on quartiles.
```{r EDA_AREA_2}
residential_clean_df <- residential_clean_df %>%
  mutate(GBA_Bucket = case_when(GBA <= quantile(GBA,probs=c(0.25)) ~ 0,
                                GBA <= median(GBA, na.rm = TRUE) ~1,
                                GBA <= quantile(GBA,probs=c(0.75)) ~ 2,
                                GBA <= quantile(GBA,probs=c(0.90)) ~ 3,
                                GBA > quantile(GBA,probs=c(0.90)) ~ 4)) %>%
  mutate(LANDAREA_Bucket = case_when(LANDAREA <= quantile(LANDAREA,probs=c(0.25)) ~ 0,
                                LANDAREA <= median(LANDAREA, na.rm = TRUE) ~1,
                                LANDAREA <= quantile(LANDAREA,probs=c(0.75)) ~ 2,
                                LANDAREA <= quantile(LANDAREA,probs=c(0.90)) ~ 3,
                                LANDAREA > quantile(LANDAREA,probs=c(0.90)) ~ 4))
# remove LAND_AREA and GBA
residential_clean_df <- residential_clean_df %>%
  select(-c(LANDAREA, GBA, SALE_NUM))

```  
  
### Missing Values.  

Draw a pairwise graph for checking any correlations.  

```{r missing_1}
summary(residential_clean_df)
```  
There are 38 rows with missing values excluding PRICE columns. Let's drop them.
```{r missing_values}
residential_clean_df <- residential_clean_df %>%
  drop_na(-PRICE)

residential_clean_df <- residential_clean_df %>%
  filter(PRICE != 0)
```  
### dummyfication.  

Convert all factor colmns to dummy variables.  

```{r dummy_1}
residential_clean_df <- residential_clean_df %>%
  select(-QUALIFIED)
factor_columns <- residential_clean_df %>% 
  Filter(f = is.factor) %>%
  names
dv <- dummyVars('~.', data = residential_clean_df, fullRank = TRUE)
res_dummy_df <- data.frame(predict(dv, newdata = residential_clean_df))
```  

### correlations.  

```{r corr_1, fig.height=10}
rcorr_matrix <- res_dummy_df %>%
  select(-OBJECTID, -PRICE) %>%
  as.matrix() %>%
  rcorr()
corrplot(rcorr_matrix$r, type='upper', order = 'hclust',tl.cex = 0.8)
```  

```{r corr_2}
high_corr_df <- as.data.frame(rcorr_matrix$r) %>% 
  rownames_to_column(var = 'feat1') %>%
  gather(key = 'feat2', value = 'corr', -feat1) %>%
  filter(abs(corr) >= 0.7, feat1 != feat2)
p_value_df <- as.data.frame(rcorr_matrix$P) %>% 
  rownames_to_column(var = 'feat1') %>%
  gather(key = 'feat2', value = 'p', -feat1) %>%
  filter(feat1 != feat2)

multi_colinearity <- high_corr_df %>%
  left_join(p_value_df) %>%
  arrange(feat1, feat2)
multicol_feature <- unique(multi_colinearity$feat1)

rcorr_matrix_2 <- res_dummy_df %>%
  select(!!multicol_feature, PRICE) %>%
  as.matrix() %>%
  rcorr()
corrplot(rcorr_matrix_2$r, type='upper', order = 'hclust',tl.cex = 0.6,tl.srt = 70)
```  

None of these 8 features indepently have high correlatio with independent variable PRICE.
We will remove below features.  
1. etxwall_coding.extwall_siding
2. intwall_coding.intwall_other  
3. KITCHENS  
4. structure_coding.str_single  
  
```{r corr_3}
res_dummy_df_uncorr <- res_dummy_df %>%  select(-etxwall_coding.extwall_siding,-intwall_coding.intwall_other, -KITCHENS,-structure_coding.str_single)

```  

### Zerovariance columns.  


```{r NZV}
nzv_cols <- res_dummy_df_uncorr %>%
  select(-PRICE) %>%
  nearZeroVar(names = TRUE, freqCut = 99/1)

#res_dummy_df_uncorr <- res_dummy_df_uncorr %>% select(-!!nzv_cols) 
```

##Prepare the dataset.  

## Test and train dataset.

### Removing outliers.  

```{r outliers_1}
res_data_modelling <- res_dummy_df_uncorr %>%
  filter(!is.na(PRICE))
```

Below columns are not one hot encoded. They are continuous variables.Need to remove outliers defined as mean +/- 1.5*sd.  

ROOMS.  
NUM_UNITS.  
BEDRM  
STORIES  
FIREPLACES  
BATH_ROOM_TOTAL  
AGE  
SALE_YEAR  
and  
PRICE.  

```{r outlier_PRICE}
res_data_modelling %>%
  select(PRICE) %>%
  ggplot(data = ., aes(y = PRICE)) +
  geom_boxplot()
res_data_modelling %>%
  select(PRICE) %>%
  ggplot(data = ., aes(x = PRICE)) +
  geom_histogram(bins=60) +
  labs(title = 'Distribution of sale prices')

res_data_modelling %>%
  filter(PRICE > quantile(PRICE,1/100),
         PRICE < quantile(PRICE,99/100)) %>%
  select(PRICE) %>%
  ggplot(data = ., aes(x = PRICE)) +
  geom_histogram(bins=60)  +
  labs(title = 'Distribution of sale prices after removing extremen 1% on both sides')


PRICE_outlier_rows <- which(res_data_modelling$PRICE < quantile(res_data_modelling$PRICE,1/100)|
        res_data_modelling$PRICE > quantile(res_data_modelling$PRICE,99/100))

set.seed(12309)
# Take log of PRICE for prediction as PRICE need to be positive.
res_data_modelling <- res_data_modelling%>%
  mutate(PRICE_LOG = log(PRICE))

```  
PRICE is dependent variable and only positive value makes sense. Hence it needs to be log transfomred. Looking at the above 3 graphs top and bottom 1 percentile can be removed as outliers.  

```{r ROOMS}
res_data_modelling %>%
  select(ROOMS) %>%
  ggplot(data = ., aes(y = ROOMS)) +
  geom_boxplot() +
  labs(title = 'Distribution of ROOMS')
res_data_modelling %>%
  select(ROOMS) %>%
  ggplot(data = ., aes(x = ROOMS)) +
  geom_histogram(bins=15)+
  labs(title = 'Residences by number of rooms', y = 'Residence count')
ROOMS_outlier_rows <- which(res_data_modelling$ROOMS == 0 |
        res_data_modelling$ROOMS >12 )
```  
From the box plot, rooms greater than 11 on upper side are outliers.  
Also rooms ==0 are incorrect as they have bathroom_total, bedroom and stories non zero.  

```{r BEDRM}
res_data_modelling %>%
  select(BEDRM) %>%
  ggplot(data = ., aes(y = BEDRM)) +
  geom_boxplot() +
  labs(title = 'Bedroom disributions')
res_data_modelling %>%
  select(BEDRM) %>%
  ggplot(data = ., aes(x = BEDRM)) +
  geom_histogram(bins=35) +
  labs(title = 'Residences by bedrooms')
BEDROOMS_outlier_rows <- which(res_data_modelling$BEDRM == 0 |
        res_data_modelling$BEDRM >12 )
```  
From the box plot, BEDRM greater than 11 on upper side are outliers.  
Also BEDRM ==0 are incorrect as they have bathroom_total, bedroom and stories non zero.  

```{r STORIES}
res_data_modelling %>%
  select(STORIES) %>%
  ggplot(data = ., aes(y = STORIES)) +
  geom_boxplot() +
  labs(title = 'Distribution of stories')
res_data_modelling %>%
  select(STORIES) %>%
  ggplot(data = ., aes(x = STORIES)) +
  geom_histogram(bins=50) +
  labs(title = 'Residences by stories')
STORIES_outlier_rows <- which(res_data_modelling$STORIES > 10 )
```   

Clearly any buildings with more than 10 stories is outlier.   

```{r remove outliers}
outlier_rows <- STORIES_outlier_rows %>%
  union(BEDROOMS_outlier_rows) %>%
  union(ROOMS_outlier_rows) %>%
  union(PRICE_outlier_rows) %>%
  sort()
res_data_modelling <- res_data_modelling[-outlier_rows,]
```

 
```{r test_train_2}
trainIndex = createDataPartition(res_data_modelling$PRICE, p=0.8, list=FALSE)
train_residence_df <- res_data_modelling[trainIndex, ]
test_residence_df <-  res_data_modelling[-trainIndex, ]
train_obj <- train_residence_df %>% select(OBJECTID)
train_residence_df <- train_residence_df %>% select(-OBJECTID)
test_obj <- test_residence_df %>% select(OBJECTID)
test_residence_df <- test_residence_df %>% select(-OBJECTID)

```  


### scale data.  
```{r scale_data}
set.seed(12309)
scaled_data_model <- preProcess(train_residence_df %>%
                                  select(-PRICE, -PRICE_LOG), 
                                method = 'scale')
train_residence_df_scaled <- predict(scaled_data_model, 
                                     newdata = train_residence_df %>%
                                       select(-PRICE))
test_residence_df_scaled <- predict(scaled_data_model, 
                                    newdata = test_residence_df %>%
                                       select(-PRICE))
```  

## Run models.  

### Linear Regression.  


```{r lm_model_1}
set.seed(6969)
simple_linear_model <- train(PRICE_LOG~.,data = train_residence_df_scaled, method = 'lm')
summary(simple_linear_model)

plot(simple_linear_model$finalModel)

```  
Adjusted R-Square is 76.78% which is pretty good.  

```{r lm_mod_2}
lm_predict <- predict(simple_linear_model, test_residence_df_scaled)

error_plot(lm_predict,test_residence_df_scaled$PRICE_LOG)
```  
The model performance on test data is 70%.  

### Linear Regression with repeated cv
```{r lm_rcv_1}
set.seed(59568)
tc <- trainControl(method = 'repeatedcv', number = 10)
lm2_model <- train(PRICE_LOG~., data = train_residence_df_scaled, method = 'lm',
                   trControl = tc)
summary(lm2_model)
lm2_predict <- predict(lm2_model, test_residence_df_scaled)
error_plot(lm2_predict,test_residence_df_scaled$PRICE_LOG)
```  
There is no difference when repeatedCross validation method is used.  

### Generalised Linear Regression.  

```{r glm_1}
set.seed(5684)
tc <- trainControl(method = 'repeatedcv', number = 10)
glm_model <- train(PRICE_LOG~., data = train_residence_df_scaled, method = 'glm',
                   trControl = tc)
summary(glm_model)

glm_predict_train <- predict(glm_model, train_residence_df_scaled)
postResample(pred = glm_predict_train, obs = train_residence_df_scaled$PRICE_LOG)

glm_predict <- predict(glm_model, test_residence_df_scaled)
postResample(pred = glm_predict, obs = test_residence_df_scaled$PRICE_LOG)
error_plot(glm_predict,test_residence_df_scaled$PRICE_LOG)
```  

### Random Frest.

```{r rf_1}
set.seed(90898)
rf1 <- randomForest(PRICE_LOG~., data = train_residence_df_scaled, 
                    ntree=10,
                    mtry = 3,
                    importance = TRUE)
summary(rf1)
pred_rf <- predict(rf1, test_residence_df_scaled)
postResample(pred = pred_rf, obs = test_residence_df_scaled$PRICE_LOG)
error_plot(pred_rf,test_residence_df_scaled$PRICE_LOG)
varImpPlot(rf1, main = 'Variable importance', cex = 0.6)
```  

### Xtreme gradient boosting.  

```{r xgb_1}
xg_model <- xgboost(data = data.matrix(train_residence_df_scaled %>%
                                         select(-PRICE_LOG)), 
                    eta = 1, objective = 'reg:linear', 
                    eval_metric = 'rmse', nround=20, 
                    label = train_residence_df_scaled$PRICE_LOG)
summary(xg_model)
xgb_pre <- predict(xg_model, data.matrix(test_residence_df_scaled %>%
                                         select(-PRICE_LOG)))
postResample(pred = xgb_pre, test_residence_df_scaled$PRICE_LOG)

error_plot(xgb_pre,test_residence_df_scaled$PRICE_LOG)

```

```{r model_eval}
t <- cbind(test_residence_df_scaled$PRICE_LOG, xgb_pre)
colnames(t) <- c('act','pre')
ggplot(data = data.frame(t), aes(x = act, y = pre)) +
  geom_point()


t1 <- cbind(test_residence_df_scaled$PRICE_LOG, pred_rf)
colnames(t1) <- c('act','pre')
ggplot(data = data.frame(t1), aes(x = act, y = pre)) +
  geom_point()
```  

### Regularization regression.  

LASSO, Ridge regression and Elastic regresssion.  

```{r lasso_1}
lasso_model <- cv.glmnet(data.matrix(train_residence_df_scaled %>%
                                         select(-PRICE_LOG)),
                         train_residence_df_scaled$PRICE_LOG, 
                         family = 'gaussian', alpha=1)
summary(lasso_model)
lasso_pre <- predict(lasso_model, data.matrix(test_residence_df_scaled %>%
                                         select(-PRICE_LOG)))
postResample(pred = lasso_pre, test_residence_df_scaled$PRICE_LOG)

t2 <- cbind(test_residence_df_scaled$PRICE_LOG, lasso_pre)
colnames(t2) <- c('act','pre')
ggplot(data = data.frame(t2), aes(x = act, y = pre)) +
  geom_point()

error_plot(lasso_pre,test_residence_df_scaled$PRICE_LOG)
```  

```{r ridge_1}
ridge_model <- cv.glmnet(data.matrix(train_residence_df_scaled %>%
                                         select(-PRICE_LOG)),
                         train_residence_df_scaled$PRICE_LOG, family = 'gaussian', alpha=0)
summary(ridge_model)
ridge_pre <- predict(ridge_model, data.matrix(test_residence_df_scaled %>%
                                         select(-PRICE_LOG)))
postResample(pred = ridge_pre, test_residence_df_scaled$PRICE_LOG)

t3 <- cbind(test_residence_df_scaled$PRICE_LOG, ridge_pre)
colnames(t3) <- c('act','pre')
ggplot(data = data.frame(t3), aes(x = act, y = pre)) +
  geom_point()
```  
```{r elastic_1}
ridge_model <- cv.glmnet(data.matrix(train_residence_df_scaled %>%
                                         select(-PRICE_LOG)),
                         train_residence_df_scaled$PRICE, family = 'gaussian')
summary(ridge_model)
ridge_pre <- predict(ridge_model, data.matrix(test_residence_df_scaled %>%
                                         select(-PRICE_LOG)))
postResample(pred = ridge_pre, test_residence_df_scaled$PRICE_LOG)

error_plot(ridge_pre,test_residence_df_scaled$PRICE_LOG)
```
